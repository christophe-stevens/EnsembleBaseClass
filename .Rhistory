setwd("C:\Users\chris\OneDrive - Imperial College London\PHD\PHD Ensemble Package\New Package\EnsembleBase")
devtools::install_github("christophe-stevens/EnsembleBaseClass")
# Data preparation
require(mlbench)  # install.packages("mlbench")
data(PimaIndiansDiabetes)
dataset <- PimaIndiansDiabetes
# The response variable should be a vector with 0 and 1, and as a factor.
dataset$diabetes <- as.factor(ifelse(dataset$diabetes=="pos",1,0))
myformula <- diabetes ~ insulin + age + triceps
perc.train <- 0.7
index.train <- sample(1:nrow(dataset), size = round(perc.train*nrow(dataset)))
data.train <- dataset[index.train,]
data.predict <- dataset[-index.train,]
require("EnsembleBaseClass")
myconfigs <- make.configs("knn", type="classification")
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=2)
newpred <- predict(ret, data.predict)
plot(ret)
print(ret)
validate(ret)
validate(ret, newdata= data.predict, formula = myformula)
parts <- generate.partitions(1, nrow(data.train))
myconfigs <- make.configs("svm", type="classification")
instances <- make.instances(myconfigs, parts)
ret <- Regression.CV.Batch.Fit(instances, myformula, data.train)
myconfigs <- make.configs("svm", type="classification")
myconfigs
instances <- make.instances(myconfigs, parts)
ret <- Regression.CV.Batch.Fit(instances, myformula, data.train)
myformula
ret <- Classification.CV.Batch.Fit(instances, myformula, data.train)
plot(ret)
myconfigs <- make.configs(c("knn","rf"), type="classification")
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=2)
newpred <- predict(ret, data.predict)
plot(ret)
parts <- generate.partitions(1, nrow(data.train))
myconfigs <- make.configs(c("svm","penreg"), type="classification")
instances <- make.instances(myconfigs, parts)
ret <- Classification.CV.Batch.Fit(instances, myformula, data.train)
newpred <- predict(ret, data.predict)
plot(ret)
remove.packages("EnsembleBaseClass", lib="~/R/win-library/4.0")
devtools::install_github("christophe-stevens/EnsembleBaseClass")
devtools::install_github("christophe-stevens/EnsemblePCClass")
require("EnsembleBaseClass")
require("EnsemblePCClass")
# Data preparation
require(mlbench)  # install.packages("mlbench")
data(PimaIndiansDiabetes)
dataset <- PimaIndiansDiabetes
# The response variable should be a vector with 0 and 1, and as a factor.
dataset$diabetes <- as.factor(ifelse(dataset$diabetes=="pos",1,0))
myformula <- diabetes ~ insulin + age + triceps
perc.train <- 0.7
index.train <- sample(1:nrow(dataset), size = round(perc.train*nrow(dataset)))
data.train <- dataset[index.train,]
data.predict <- dataset[-index.train,]
# training ensemble
control <- epcclass.baselearner.control(baselearners=c("knn","svm")) #c("penreg","svm","knn","nnet","gbm","rf"))
ensemble <- epcclass(formula =  myformula, data = data.train, baselearner.control= control)
plot(ensemble)
# training ensemble
control <- epcclass.baselearner.control(baselearners=c("knn","svm","rf")) #c("penreg","svm","knn","nnet","gbm","rf"))
ensemble <- epcclass(formula =  myformula, data = data.train, baselearner.control= control)
plot(ensemble)
table(pred, data.predict$diabetes)
pred <- round(predict(ensemble,newdata=data.predict))
table(pred, data.predict$diabetes)
myformula <- diabetes ~ insulin + .
# training ensemble
control <- epcclass.baselearner.control(baselearners=c("knn","svm","rf")) #c("penreg","svm","knn","nnet","gbm","rf"))
ensemble <- epcclass(formula =  myformula, data = data.train, baselearner.control= control)
str(dataset)
myformula <- diabetes ~ insulin + glucose + pregnant + triceps + mass + age + pressure
ensemble <- epcclass(formula =  myformula, data = data.train, baselearner.control= control)
plot(ensemble)
plot(ensemble)
plot(ensemble)
pred <- round(predict(ensemble,newdata=data.predict))
table(pred, data.predict$diabetes)
detach("bartMachine", unload=TRUE)
detach(bartMachine, unload=TRUE)
rm(list=ls())
options(java.parameters = "-Xmx2500m")
pkg <- c("doParallel","parallel","foreach","e1071", "gbm",
"randomForest","nnet","kknn","glmnet","bartMachine","xgboost")
sapply(pkg, library, character.only =T)
source("./R/thread_util.R")
# Data preparation
require(mlbench)  # install.packages("mlbench")
data(PimaIndiansDiabetes)
dataset <- PimaIndiansDiabetes
# The response variable should be a vector with 0 and 1, and as a factor.
dataset$diabetes <- as.numeric(ifelse(dataset$diabetes=="pos",1,0))
myformula <- diabetes ~ insulin + age + triceps
perc.train <- 0.7
index.train <- sample(1:nrow(dataset), size = round(perc.train*nrow(dataset)))
data.train <- dataset[index.train,]
data.predict <- dataset[-index.train,]
myconfigs <- make.configs(c("bart"), type="classification") #
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
newpred <- predict(ret, data.predict)
plot(ret)
validate(ret, newdata= data.predict, formula = myformula)
table(round(newpred)[,3],data.predict$diabetes)
make.configs(c("bart"), type="classification")
setwd("C:/Users/chris/OneDrive - Imperial College London/PHD/PHD Ensemble Package/New Package/EnsembleBaseClass")
setwd("~/")
setwd("C:/Users/chris/OneDrive - Imperial College London/PHD/PHD Ensemble Package/New Package/EnsembleBaseClass")
source("./R/thread_util.R")
myconfigs <- make.configs(c("bart"), type="classification") #
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
newpred <- predict(ret, data.predict)
plot(ret)
validate(ret, newdata= data.predict, formula = myformula)
table(round(newpred)[,3],data.predict$diabetes)
detach(bartMachine, unload=T)
detach("bartMachine", unload=T)
detach("package:bartMachine", unload=TRUE)
detach("package:bartMachineJARs", unload=TRUE)
options(java.parameters = "-Xmx4000M")
pkg <- c("doParallel","parallel","foreach","e1071", "gbm",
"randomForest","nnet","kknn","glmnet","bartMachine","xgboost")
sapply(pkg, library, character.only =T)
# Data preparation
require(mlbench)  # install.packages("mlbench")
data(PimaIndiansDiabetes)
dataset <- PimaIndiansDiabetes
# The response variable should be a vector with 0 and 1, and as a factor.
dataset$diabetes <- as.numeric(ifelse(dataset$diabetes=="pos",1,0))
myformula <- diabetes ~ insulin + age + triceps
perc.train <- 0.7
index.train <- sample(1:nrow(dataset), size = round(perc.train*nrow(dataset)))
data.train <- dataset[index.train,]
data.predict <- dataset[-index.train,]
myconfigs <- make.configs(c("bart"), type="classification") #
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
newpred <- predict(ret, data.predict)
plot(ret)
ret@pred
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
newpred <- predict(ret, data.predict)
rm(list=ls())
options(java.parameters = "-Xmx4000M")
pkg <- c("doParallel","parallel","foreach","e1071", "gbm",
"randomForest","nnet","kknn","glmnet","bartMachine","xgboost")
sapply(pkg, library, character.only =T)
source("./R/thread_util.R")
# Data preparation
require(mlbench)  # install.packages("mlbench")
data(PimaIndiansDiabetes)
dataset <- PimaIndiansDiabetes
# The response variable should be a vector with 0 and 1, and as a factor.
dataset$diabetes <- as.numeric(ifelse(dataset$diabetes=="pos",1,0))
myformula <- diabetes ~ insulin + age + triceps
perc.train <- 0.7
index.train <- sample(1:nrow(dataset), size = round(perc.train*nrow(dataset)))
data.train <- dataset[index.train,]
data.predict <- dataset[-index.train,]
myconfigs <- make.configs(c("bart"), type="classification") #
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
newpred <- predict(ret, data.predict)
plot(ret)
validate(ret, newdata= data.predict, formula = myformula)
table(round(newpred)[,3],data.predict$diabetes)
table(round(newpred)[,1],data.predict$diabetes)
parts <- generate.partitions(1, nrow(data.train))
myconfigs <- make.configs(c("nnet","rf","svm","gbm","knn", "penreg","xgboost","bart"), type="classification")
instances <- make.instances(myconfigs, parts)
ret <- Classification.CV.Batch.Fit(instances, myformula, data.train)
newpred <- predict(ret, data.predict)
plot(ret)
plot(ret)
myconfigs <- make.configs(c("bart"), type="classification")
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
newpred <- predict(ret, data.predict)
plot(ret)
validate(ret, newdata= data.predict, formula = myformula)
table(round(newpred)[,1],data.predict$diabetes)
parts <- generate.partitions(1, nrow(data.train))
myconfigs <- make.configs(c("nnet","rf","svm","gbm","knn", "penreg","xgboost"), type="classification")
instances <- make.instances(myconfigs, parts)
ret <- Classification.CV.Batch.Fit(instances, myformula, data.train)
newpred <- predict(ret, data.predict)
plot(ret)
rm(list=ls())
options(java.parameters = "-Xmx4000M")
pkg <- c("doParallel","parallel","foreach","e1071", "gbm",
"randomForest","nnet","kknn","glmnet","bartMachine","xgboost")
sapply(pkg, library, character.only =T)
source("./R/thread_util.R")
myconfigs <- make.configs(c("bart"), type="classification")
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
newpred <- predict(ret, data.predict)
plot(ret)
validate(ret, newdata= data.predict, formula = myformula)
table(round(newpred)[,1],data.predict$diabetes)
rm(list=ls())
options(java.parameters = "-Xmx4000M")
pkg <- c("doParallel","parallel","foreach","e1071", "gbm",
"randomForest","nnet","kknn","glmnet","bartMachine","xgboost")
sapply(pkg, library, character.only =T)
source("./R/thread_util.R")
# Data preparation
require(mlbench)  # install.packages("mlbench")
data(PimaIndiansDiabetes)
dataset <- PimaIndiansDiabetes
# The response variable should be a vector with 0 and 1, and as a factor.
dataset$diabetes <- as.numeric(ifelse(dataset$diabetes=="pos",1,0))
myformula <- diabetes ~ insulin + age + triceps
perc.train <- 0.7
index.train <- sample(1:nrow(dataset), size = round(perc.train*nrow(dataset)))
data.train <- dataset[index.train,]
data.predict <- dataset[-index.train,]
myconfigs <- make.configs(c("bart"), type="classification")
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
newpred <- predict(ret, data.predict)
plot(ret)
validate(ret, newdata= data.predict, formula = myformula)
table(round(newpred)[,1],data.predict$diabetes)
rm(list=ls())
options(java.parameters = "-Xmx4000M")
pkg <- c("doParallel","parallel","foreach","e1071", "gbm",
"randomForest","nnet","kknn","glmnet","bartMachine","xgboost")
sapply(pkg, library, character.only =T)
source("./R/thread_util.R")
# Data preparation
require(mlbench)  # install.packages("mlbench")
data(PimaIndiansDiabetes)
dataset <- PimaIndiansDiabetes
# The response variable should be a vector with 0 and 1, and as a factor.
dataset$diabetes <- as.numeric(ifelse(dataset$diabetes=="pos",1,0))
myformula <- diabetes ~ insulin + age + triceps
perc.train <- 0.7
index.train <- sample(1:nrow(dataset), size = round(perc.train*nrow(dataset)))
data.train <- dataset[index.train,]
data.predict <- dataset[-index.train,]
myconfigs <- make.configs(c("bart"), type="classification")
ret <- Classification.Batch.Fit(myconfigs, myformula, data.train, ncores=8)
plot(ret)
newpred <- predict(ret, data.predict)
table(round(newpred)[,1],data.predict$diabetes)
myconfigs <- make.configs(c("nnet"), type="classification")
parts <- generate.partitions(1, nrow(data.train))
myconfigs <- make.configs(c("nnet"), type="classification")
instances <- make.instances(myconfigs, parts)
ret <- Classification.CV.Batch.Fit(instances, myformula, data.train)
newpred <- predict(ret, data.predict)
plot(ret)
ret <- Classification.CV.Fit(myconfigs[[1]], myformula, data.train, parts)
newpred <- predict(ret, data.predict)
myconfigs[[1]]
parts
